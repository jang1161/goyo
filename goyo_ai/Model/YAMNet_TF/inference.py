import tensorflow as tf
import numpy as np
import os
from typing import List, Dict
import librosa

from layers import YAMNetLayer

MODEL_PATH = 'checkpoints/best_model.keras'
TOTAL_CHUNKS = 5
AUDIO_LENGTH_SAMPLES = 15600
SAMPLE_RATE = 16000

SENSOR_CONFIGS: Dict[int, str] = {
    1: "Air_conditioner",
    2: "Hair_dryer",
    3: "Microwave",
    4: "Refrigerator_Hum",
    5: "Vacuum"
}

CLASS_NAMES = [
    'Air_conditioner',
    'Hair_dryer',
    'Microwave',
    'Others', 
    'Refrigerator_Hum', 
    'Vacuum',
]

# ë‚˜ì¤‘ì— ì‹¤ì‹œê°„ ì—°ê²°ë˜ë©´ ì§€ì›Œë„ ë  í•¨ìˆ˜
def preprocess_audio_file(file_path):
    try:
        wav_data, _ = librosa.load(file_path, sr=SAMPLE_RATE, mono=True)

        if len(wav_data) < AUDIO_LENGTH_SAMPLES:
            # ì§§ìœ¼ë©´ ë’¤ì— 0ìœ¼ë¡œ íŒ¨ë”©
            wav_data = np.pad(wav_data, (0, AUDIO_LENGTH_SAMPLES - len(wav_data)))
        else:
            # ê¸¸ë©´ ì•ì—ì„œë¶€í„° 15600ê°œë§Œ ìë¦„ (ì‹¤ì‹œê°„ ì²­í¬ ì‹œë®¬ë ˆì´ì…˜)
            wav_data = wav_data[:AUDIO_LENGTH_SAMPLES]
            
        return wav_data.astype(np.float32)
        
    except Exception as e:
        print(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ ({file_path}): {e}")
        # ì‹¤íŒ¨ ì‹œ 0ìœ¼ë¡œ ì±„ìš´ ë”ë¯¸ ë°˜í™˜
        return np.zeros(AUDIO_LENGTH_SAMPLES, dtype=np.float32)


def load_trained_model(model_path: str) -> tf.keras.Model:
    if not os.path.exists(model_path):
        print(f"error: ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None
    
    try:
        model = tf.keras.models.load_model(
            model_path,
            custom_objects={'YAMNetLayer': YAMNetLayer}  # custom_objectsì— ì„í¬íŠ¸í•œ YAMNetLayer í´ë˜ìŠ¤ë¥¼ ì „ë‹¬
        )
        print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")
        return model
    except Exception as e:
        print(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None
    

def run_final_filtering(
    model: tf.keras.Model,
    mic_id: int, 
    buffer_of_chunks: List[np.ndarray]
) -> None:

    expected_class = SENSOR_CONFIGS.get(mic_id)

    if len(buffer_of_chunks) != TOTAL_CHUNKS:
        print(f"ì²­í¬ ê°œìˆ˜ ì˜¤ë¥˜")
        return

    input_batch = np.array(buffer_of_chunks) # ë¶„ë¥˜ ëª¨ë¸ ì‘ë™ (5ê°œ ì²­í¬ë¥¼ ë°°ì¹˜ë¡œ ë¬¶ì–´ 1ë²ˆ ì‹¤í–‰)
    prob_outputs = model.predict(input_batch, verbose=0) # ê²°ê³¼ shape: (5, 10)
    
    predicted_indices = np.argmax(prob_outputs, axis=1) # í™•ë¥ ì„ í´ë˜ìŠ¤ ì¸ë±ìŠ¤ë¡œ ë³€í™˜

    match_count = 0
    
    print(f"\n--- [Mic {mic_id}: {expected_class}] ì¶”ë¡  ê²°ê³¼ ---")
    
    for i, idx in enumerate(predicted_indices):
        pred_class = CLASS_NAMES[idx]
        is_match = (pred_class == expected_class)
        
        if is_match:
            match_count += 1
            
        print(f"   Chunk {i+1}: {pred_class} [{'O' if is_match else 'X'}]")

    if (match_count/TOTAL_CHUNKS)>=0.8:
        print(f"ANC ì‘ë™ ì‹ í˜¸ ì „ì†¡ ({match_count}/{TOTAL_CHUNKS} ì¼ì¹˜)")
    else:
        print(f"ì‹ í˜¸ ë¬´ì‹œ ({match_count}/{TOTAL_CHUNKS} ì¼ì¹˜)")

#ì˜ˆì‹œì‹¤í–‰ì½”ë“œ - ìˆ˜ì •í•„ìš”
if __name__ == "__main__":
   model = load_trained_model(MODEL_PATH) 
   if model:
        TEST_DIR = "/Users/kimtaerim/Desktop/GOYO/goyo_ai/Dataset/Test_data" 
        
        TEST_FILENAMES = [
            "cleaner2.m4a",
            "cleaner2.m4a",
            "cleaner2.m4a",
            "cleaner2.m4a",
            "miaow_16k.wav"
        ]
        
        print(f"\nğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘... ({TEST_DIR})")
        real_audio_buffer = []
        
        for fname in TEST_FILENAMES:
            full_path = os.path.join(TEST_DIR, fname)
            audio_chunk = preprocess_audio_file(full_path)
            real_audio_buffer.append(audio_chunk)

        TARGET_MIC_ID = 5 
        print(f"ğŸ“¡ Mic {TARGET_MIC_ID} ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")
        run_final_filtering(model, mic_id=TARGET_MIC_ID, buffer_of_chunks=real_audio_buffer)